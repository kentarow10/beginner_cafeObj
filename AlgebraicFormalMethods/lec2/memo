疑問点
weakfairnessはenable(T)になったらいつかはTが適用される、ぐらいの理解しかできていませ
ん。
(<> [] enabled(T)) -> ([] <> applied(T))
wait(p1) |-> crit(p1)
この式も、waitになったらやがてcritになる、という意味で似たようなイメージを持ちます。

fairness（公平性）は、仮定です。検査対象の性質ではありません。
一方、lockout  freedom propertyは、検査対象の性質です。
fairnessの仮定のもとで、lockout freedom propertyを検査します。
fairnessを満たさないもの、たとえば、ある時点以降１つのプロセスだけしか選ばれないものは、性質を満たしていても満たしていなくても、興味の対象からあ外れることになります。
ここまでは良いですか？

A |-> Bは、[] (A -> <> B)です。
仮定と検査対象の違い、それにこのLTL式と
(<> [] A) -> ([] <> B)との違いが分かれば上記の疑問は解消するのではと。



１．[] (A -> <> B)は、A -> <> Bがどんな時点でも成り立つことを意味します。
A -> <> Bは、Aが一度成り立ったならば、そのうちBが成り立つです。
Aは、成り立ち続ける必要はないです。

Aがあつ時点で成り立ち、次の時点で成り立たなくなっても、一度成り立ったので、A -> <> Bの条件を満たすので、
<>BのそのうちBが成り立つ必要がある、という要件を満たす必要があります。

A -> <> Bに[]がついているので、どんなときでも、Aが一度成り立ったならば、そのうちBが成り立つです。
Aの成り立つ回数とBの成り立つ回数には関係はないです。
前後関係のみが重要です。Aが成り立った後、Bが成り立ち、それがいつでも起こるです。

２．(<> [] A) -> ([] <> B)
この前提条件<> [] Aは、Aがある地点からずっと成り立ち続ける、です。
頻繁に成り立つが、頻繁に成り立たないのであれば、条件は満たされません。

[] <> Bは、Bが頻繁に（無限に）成り立つです。
ある時点からAがずっと成り立ち続けるのであれば、Bは頻繁に成り立つ、ということを言っています。

fairnessで出てくる式が何を言っているのか、というところが知りたいです。

Weak fairnessの場合だと、
ある地点からA（ある状態遷移の条件）がずっと成り立ち続けるのに、
Bが成り立たない（その状態遷移が選ばれない）ような無限列は検査の対象から除外する、
と考えたほうが分かりやすいと思います。
状態遷移が無限に選ばれないということは、有限しか選ばれないので、
ある時点から選ばれないことになります。なので、「状態船が選ばれない」で同じことを表現しています。

weakとstrongも式の違いから、どんな違いが生まれているのかがわかりませんでした。
([] <> enabled(T)) -> ([] <> applied(T))

Strong fairnessの場合、前提条件が[]
<>Aになります。条件が永遠になり続ける必要はなく、頻繁に（途中で成り立たなくなるかもしれないが、何度も）成り立つ、です。

ここまではどうでしょうか？

もし、OKだとすれば、以下のLTL式を図示してください（手書き）。
１．A |-> B
２．(<> [] A) -> ([] <> B)
３．([] <> A) -> ([] <> B)

--

K, π^i |= φ

(pc[p1]: rs) (pc[p2]: rs) (tmp[p1]: emp) (tmp[p2]: emp) (queue: emp);
(pc[p1]: rs) (pc[p2]: ws) (tmp[p1]: emp) (tmp[p2]: emp) (queue: p2);
(pc[p1]: rs) (pc[p2]: cs) (tmp[p1]: emp) (tmp[p2]: emp) (queue: p2);
(pc[p1]: rs) (pc[p2]: ds) (tmp[p1]: emp) (tmp[p2]: emp) (queue: p2);
(pc[p1]: ws) (pc[p2]: ds) (tmp[p1]: emp) (tmp[p2]: emp) (queue: p2 p1);
(
(pc[p1]: ws) (pc[p2]: rs) (tmp[p1]: emp) (tmp[p2]: emp) (queue: emp);
(pc[p1]: ws) (pc[p2]: ws) (tmp[p1]: emp) (tmp[p2]: emp) (queue: p2);
(pc[p1]: ws) (pc[p2]: cs) (tmp[p1]: emp) (tmp[p2]: emp) (queue: p2);
(pc[p1]: ws) (pc[p2]: ds) (tmp[p1]: emp) (tmp[p2]: emp) (queue: p2);
)^∞

K, π |= Τ Ц inCs(p1)のπの反例

s_0 = (pc[p1]: rs) (pc[p2]: rs) (tmp[p1]: emp) (tmp[p2]: emp) (queue: emp)
s_k = (pc[p1]: ws) (pc[p2]: ds) (tmp[p1]: emp) (tmp[p2]: emp) (queue: p2 p1)
s_{k+1} = (pc[p1]: ws) (pc[p2]: rs) (tmp[p1]: emp) (tmp[p2]: emp) (queue: emp)
s_m = (pc[p1]: ws) (pc[p2]: ds) (tmp[p1]: emp) (tmp[p2]: emp) (queue: p2)

の時の
π = s_0; ...; s_k; (s_{k+1}; ...; s_m)^∞


()
--
良いと思います。
K, π |= Τ Ц inCs(p1) を満たさないπの具体例（反例）を示してください。
s_0; ...; s_k; (s_{k+1}; ...; s_m)^∞
の形式で表現可能です。

緒方

良いと思います。
このクリプケ構造をKとします。
K |= Τ Ц inCs(p1)
は、成り立ちますか、それともそうではないですか？
定義に従って解答するようにしてください。
今回も解答を手書きするようにしてください。

ーー
CafeOBJ（あるいはMaude）のop宣言を使うと、
op _,_|=_ : Kripke InfStateSeq LTLFormula -> Bool .
のように宣言される、３引数のブール値を返す関数を定義します。

この説明でだいぶ理解が進みました。

「K, π |= φ が成り立つ場合」とありますが、成り立つというのは
「K,π(の内容・情報)からφが真であるということが言える」という感じで理解しています。

電車の例でいうと、走行中から始まるとして、
φ1を「電車のドアが閉じている」、φ2を「電車が駅に停止している」

K, π^i |= φ2がなりたつ
π(i) = 状態：(停車中,ドア閉じている)
π(i+1) = 状態：(停車中,ドア空いている)
π(i+2) = 状態：(停車中,ドア空いている)
・
・

K, π^j |= φ1が成り立ち続ける(K, π^i |= φ2がなりたつまで)
π(0) = 状態：（走行中,ドア閉じている）
π(1) = 状態：（走行中,ドア閉じている）
・
・
π(i-1) = 状態：（走行中,ドア閉じている）

K, πから φ1 Ц φ2 が成り立つ(=K, π |= φ1 Ц φ2 が成り立つ)

--
p10では、LTL式の意味を定義しています。
そのために、まず、クリプケ構造K、状態（Kに含まれるSの要素）の無限列π、LTL式φの間の関係（３項関係）を定義します。
CafeOBJ（あるいはMaude）のop宣言を使うと、
op _,_|=_ : Kripke InfStateSeq LTLFormula -> Bool .
のように宣言される、３引数のブール値を返す関数を定義します。

K, π |= φ が成り立つ場合、Kとπはφを満たす、と呼びます。

１．K, π |= Τ（どんなKとπも常にΤを満たす、ということを定義します。）
２．πの先頭の要素（状態）に原子命題pが割り当てられていれば（つまり、p ∈ L(π(0))ならば）、そしてその時に限り、K, π |= pは成り立つ。
π(0)は、状態の無限列πの先頭の状態です。p.6参照。L(π(0))は、先頭の状態に割り当てられている原子命題の集合です。
以降では、「そしてその時に限り」は省略します。
３．K, π |= φ が成り立たなければ、K, π |= ￢φ は成り立つ。
４．K, π |= φ1が成り立ち、かつ、K, π |= φ2が成り立てば、K, π |= φ1 ∧ φ2 は成り立つ。
５．K, π^1 |= φ が成り立てば、K, π |= 〇 φ は成り立つ。
ここで、πをs_o, s_1, s2, ...とすると、π^1は、s_1, s_2,
...です。p.6参照。〇はnext時相接続子（演算子）と呼ばれます。最初の状態を削除し、次の状態からはじまる状態の無限列で成り立つので。
６．K, π^i |= φ2が成り立ち、j < i であるすべてのjで、K, π^j | = φ1がなりたてば、K, π |= φ1 Ц φ2 はなりたつ。
K, π^i |= φ2がなりたつようになるまで、K, π^j |= φ1が成り立ち続ける、といったことを表しています。
たとえば、φ1を「電車のドアが閉じている」、φ2を「電車が駅に停止している」とします。
「電車のドアが閉じている」 Ц 「電車が駅に停止している」
は、走行中は電車のドアは常に閉じていて、そのうち駅に到着して停止する、ということを表しています。
（駅で停止したときにドアが開くかどうかについては言及してはいません。開くかもしれないし、閉じたままかもしれないです。）

そして、すべての計算πについて、K, π |= φ が成り立てば、K |= φと書くことにします。
Kは、φを満たす、呼びます。
電車の動作をKで記述したとすると、
K |= 「電車のドアが閉じている」 Ц 「電車が駅に停止している」
は、その電車は、走行中は電車のドアは常に閉じていて、そのうち駅に到着して停止する、という性質を満たすことを表します。

p.11に、〇 φ と φ1 Ц φ2 を図示したものを示しています。

緒方教授

・πが出てきているのがよくわからなかったです。πにおいてLTLが成り立つ、ぐらいの認識でいいのでしょうか？
・LTL式の具体的なイメージを掴みたいのですが、2より、inWs(p1)とinCs(P2)がLTL式ということになるでしょうか？

よろしくお願いします。


2020/08/12 0:19、Kazuhiro Ogata <ogata@jaist.ac.jp>のメール:

脇さん、

p.9は、linear temporal logic（線形時相論理、LTL）の構文（シンタックス）についてです。
１．Τ（トップ）はLTL式です。（LTLにおける真です。）
２．原子命題 p ∈ P はLTL式です。
３．φをLTL式とすれば、￢φはLTL式です。
４．φ1とφ2をLTL式とすれば、φ1 ∧ φ2はLTL式です。
５．φをLTL式とすれば、〇 φ はLTL式です。
６．φ1とφ2をLTL式とすれば、φ1 Ц φ2はLTL式です。（ここでは、Цという記号を使っていますが、UntilのUのことです。）

LTL式（線形時相論理式）の見た目についての定義です。

ここまではどうですか？

緒方

それでは、p.8から確認していきましょう。
π：Tの元となるようなSの要素の無限列

状態の無限列です。なので、「Sの要素の無限列」との認識は正しいです。
その前の「Tの元となるような」という表現が、正確に理解されているかどうか若干不明な感じです。

状態の無限列で、すべての隣り合う状態を組（ペア）としてみたとしたら、それらはTの元になっている、といった感じです。
なので、状態の無限列を、s_0; s_1; s2; ...; s_i; s_{i+1}; ... と書いた場合、(s_0,
s_1)、(s_1, s_2)、…、(s_i, s_{i+1})、…はすべてTの元（状態遷移）です。
一般化すると、すべてのi ∈ Natに対し、(s_i, s_{i+1}) ∈ Tということになります。
ちなみに、Tの元 (s_i, s_{i+1})
は、s_iからs_{i+1}に１回の（アトミックな、あるいは不可分な）ステップで状態遷移可能であることを表しています。
なので、s_0; s_1; s2; ...; s_i; s_{i+1}; ...
は、s_0から、s_1に移動し、次にs_2に移動し、そのうちs_iに移動し、続いてs_{i+1}に移動し、…ということを表しています。
別の言葉で説明すると、システムの状態の移り変わり（状態遷移の列）を表しています。
s_0が初期状態のとき、そのような状態の無限列を計算と呼ぶことにしています。

ここまでどうでしょうか？
不明な箇所があれば聞いてください。

p.8～11の自分の理解

p.8
π：Tの元となるようなSの要素の無限列
A computation of a K：π(0)(=s0)がIの元であるようなπ
Bold_P：全てのπ
Bold_C：π(0)がIの元であるような全てのπ
Bold_K：全てのK

p.9
・φが出てきたあたりで何をやっているのかが全くわからなくなっています。

φの定義を行う。
φは全部で6個の性質を表す？？
Bold_F：全てのφ

p.10
πであるということからトートロジー（常に真）ということが言える、とはどういう意味か？
iffで右側の状態を左側の記号で表す、と定義している
π(0)がIの元であるような全てのπにおいては、πであるということからφであるということが言える？

p.11
○φのイメージ
πを○φで表すとき、φはπ^1を表す

φ1Uφ2のイメージ
図からイメージがつかめず。



プロセスp1がwsにいるとか、プロセスp2がcsにいるとかは原子命題です。
これらを、ぞれぞれ、inWs(p1)とinCs(P2)で表現することにします。
つまり、inWs(p1)とinCs(P2)は、原子命題です（原子命題の集合Pの要素です）。
ある状態sで、p1はwsに、p2はcsにいるとすると、inWs(p1) ∈ L(s)で、inCs(p2) ∈ L(s) です。

イベントは、状態遷移につける名前です。
lecture note 2以降で出てきます。

p.8～11にかけてはどうでしょうか？

p7で不明な箇所
・原子命題とはそれ以上分解できない最も簡単な命題。イベントとは何でしょうか？


脇さん、

Rは、e1についてはS1の全ての要素で定義されているときtotalであるからだと思います。

はい。

・3行目は前二つのカッコが条件のようなもので三つ目のカッコがRの要素という認識です。

(∀x∈Nat)(∃y∈Nat) p(x,y)

と同じ構造をしています。ここで、Natは、自然数の集合とします。
どんな（すべての）自然数xにとって、p(x,y)を満たす自然数yが存在する、と解釈します。
より具体的には、

(∀x∈Nat)(∃y∈Nat) x < y

です。どんな自然数でも、それより大きな自然数は存在するので、この論理式は常に成り立ちます。

スライドで用いている論理式に相当するものを記述すると以下のようになります。

(∀x∈Nat)(∃y∈Nat) (x,y)∈R

ここで、R⊆Nat×Natです。どんな自然数でも、その自然数を第１要素とする組がRに存在する、と解釈します。
このためtotalです。
関数がtotalであるのと同じ感じです。

・5行目はπが、Sの要素を自由に並べたもの(何個でも良い)を表すという認識です。

πは、集合Sの要素の無限列です。
無限なので、何個でもよいわけではなくので、長さが１００の列のような有限列は対象外です。

・Uはそれ以降の使われ方も含めてどんなものなのか不明です。

原子命題（の名前）とイベント（の名前）を、同じものとして扱いため（原子命題の集合とイベントの集合の和集合を求めたり）、
Uを用意して、原子命題の集合とイベントの集合をUの部分集合として扱っています。
lecture note 1では、活躍しないので、Uの要素は原子命題（の名前）であると思えば十分です。

p.7で不明な箇所はありますか？
ちなみに、Sを入力とし、2^Pを出力とする、は厳密には間違っています。
関数の型がA→Bとは、Aの要素を引数（入力）にとり、Bの要素を結果として返す関数です。
S→2^Pだと、Sの要素（つまり状態）を引数にとり、2^Pの要素（原子命題の集合）を結果として返す関数です。
p.7の下の図に、{q1,q2,q3}とあるのは、ラベリング関数Lがその図のその状態を引数にとると、{q1,q2,q3}（原子命題の集合）を結果として返す、ということを意味しています。

緒方


On Mon, Aug 10, 2020 at 10:22 PM WakiKentaro <kenfan.fun@icloud.com> wrote:

緒方教授

R = {(a, 0), (a, 1), (b,1), (c, 0)}はtotalです。
R = {(b,0), (b,1), (c, 0), (c, 1)}はttotalではありません。
何故ですか？

Rは、e1についてはS1の全ての要素で定義されているときtotalであるからだと思います。

P6で不明な点・理解に自信がない点は以下です。
・3行目は前二つのカッコが条件のようなもので三つ目のカッコがRの要素という認識です。
・5行目はπが、Sの要素を自由に並べたもの(何個でも良い)を表すという認識です。
・Uはそれ以降の使われ方も含めてどんなものなのか不明です。

よろしくお願いいたします。


2020/08/10 21:35、Kazuhiro Ogata <ogata@jaist.ac.jp>のメール:

p.6は、以降で必要となる基本的なことを定義しています。
S1とかS2とかは、どんな集合でも構いません。
要素が状態である必要もないです。
… is totall iff …
は、iffの左側を右側のように定義すると読みます。
iffはif and only ifで等価という意味ですが、iffの左側が未定義のもので、左側は定義済みの場合、上記のように解釈します。
このため、… is totalの定義がiffの右側にあります。
要素をn個含む組（より一般には関係）について定義してしていますが、n = 2の場合で、S1 = {a, b, c}、S2 = {0,
1}とした場合について考えることにしましょう。


他にこのページで不明はことはありますか？